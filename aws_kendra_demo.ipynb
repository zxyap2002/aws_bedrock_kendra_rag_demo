{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code below demonstrates how AWS Bedrock and Kendra can assist in quickly searching through a large volume of documents within seconds:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Install the neccessary libraries using ``pip install -r requirements.txt`` in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Import libraries, setup aws credentials and client initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrock, AmazonKendraRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Setting up credentials\n",
    "aws_access_key_id = \"\"\n",
    "aws_secret_access_key = \"\"\n",
    "aws_session_token = \"\"\n",
    "kendra_index_id = \"\"\n",
    "kendra_data_source_id = \"\"\n",
    "\n",
    "# Initialize AWS Bedrock and Kendra client\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name='us-east-1', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, aws_session_token=aws_session_token)\n",
    "kendra_client = boto3.client('kendra', region_name='us-east-1', aws_access_key_id=aws_access_key_id,aws_secret_access_key=aws_secret_access_key, aws_session_token=aws_session_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Configure AWS Bedrock and Kendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM - AWS Bedrock - Anthropic Claude 3.0 Haiku\n",
    "claude_3_client = ChatBedrock(\n",
    "    client = bedrock_client,\n",
    "    model_id = \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    model_kwargs = { \n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure AWS Kendra\n",
    "kendra_retriever = AmazonKendraRetriever(index_id = kendra_index_id, top_k = 3, client = kendra_client, min_score_confidence = 0.5,\n",
    "    # Attribute filter is applied to filter by language language, data source or other attributes\n",
    "    attribute_filter={\n",
    "        'AndAllFilters': [\n",
    "            {\n",
    "                \"EqualsTo\": {\n",
    "                    \"Key\": \"_language_code\",\n",
    "                    \"Value\": {\"StringValue\": \"en\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"EqualsTo\": {\n",
    "                    \"Key\": \"_data_source_id\",\n",
    "                    \"Value\": {\"StringValue\": kendra_data_source_id}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    } \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Invoke AWS Bedrock with prompt template to obtain clear and friendly response for the retrieved content from AWS Kendra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt template for the Bedrock LLM when data is retrieved from Kendra\n",
    "kendra_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"You need to act as a world class document retrieval expert. I have tasks for you.\\\n",
    "    Given to you is the {context} of the document retreived from AWS Kendra. \\\n",
    "    Your answer should be related to the {question} provided. \\\n",
    "    Instead of saying based on the provided document, you should say I have found something based on the existing database. \\\n",
    "    You need to explaint clearly in point form (1, 2, n), for the document name and excerpt (Less than 50 words) for it. \\\n",
    "    Please merge the excerpt based on document name. \"\"\"\n",
    ")\n",
    "\n",
    "# Define fallback prompt template for Bedrock LLM when no Kendra data is available\n",
    "fallback_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "    No relevant information was found in the database.\n",
    "    \n",
    "    Please provide a general answer to the question:\n",
    "    {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create LLMChain with Bedrock LLM for cases when Kendra data is available\n",
    "llm_chain_with_kendra = kendra_prompt_template | claude_3_client\n",
    "\n",
    "# Create LLMChain with Bedrock LLM for cases when Kendra data is not available\n",
    "llm_chain_fallback = fallback_prompt_template | claude_3_client\n",
    "\n",
    "def ask_question(question):\n",
    "    # Retrieve context from Kendra and output the result\n",
    "    context = kendra_retriever.invoke(question)\n",
    "    print(context)\n",
    "\n",
    "    if context: # If Kendra returns results\n",
    "        # Prepare input dictionary with context and question\n",
    "        input_data = {\n",
    "            \"context\": context,  \n",
    "            \"question\": question \n",
    "        }\n",
    "        # Ask Bedrock LLM to generate an answer using the Kendra results\n",
    "        response = llm_chain_with_kendra.invoke(input=input_data)\n",
    "    else:  # If no relevant results from Kendra\n",
    "        # Prepare input dictionary with only the question\n",
    "        input_data = {\n",
    "            \"question\": question\n",
    "        }\n",
    "        # Ask Bedrock LLM to generate a general answer\n",
    "        response = llm_chain_fallback.invoke(input=input_data)\n",
    "    return response\n",
    "\n",
    "# Put your question here:\n",
    "question = \"What is the content stated in PDPA 2010 in Malaysia?\"\n",
    "answer = ask_question(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result for your answer\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
